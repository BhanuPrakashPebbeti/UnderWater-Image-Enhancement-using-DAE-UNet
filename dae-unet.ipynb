{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install timm\n!pip install pytorch_msssim","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:15.292790Z","iopub.execute_input":"2021-10-30T18:47:15.293702Z","iopub.status.idle":"2021-10-30T18:47:32.487280Z","shell.execute_reply.started":"2021-10-30T18:47:15.293665Z","shell.execute_reply":"2021-10-30T18:47:32.486038Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"import torch as T\nimport random\nfrom torch.nn import functional as F\nfrom torch import nn\nimport cv2\nfrom PIL import Image, ImageOps, ImageEnhance, __version__ as PILLOW_VERSION\nimport matplotlib.pyplot as plt\nimport timm\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, SequentialSampler\nfrom torchvision import transforms\nimport torchvision\nimport torchvision.transforms.functional as tvf\nimport numpy as np\nimport os\nfrom pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\nimport time\nimport math\nfrom prettytable import PrettyTable\nimport pandas as pd\nfrom ast import literal_eval\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\n\ndevice = \"cuda\" if T.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:32.491456Z","iopub.execute_input":"2021-10-30T18:47:32.491743Z","iopub.status.idle":"2021-10-30T18:47:32.502242Z","shell.execute_reply.started":"2021-10-30T18:47:32.491711Z","shell.execute_reply":"2021-10-30T18:47:32.501221Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, backbone = 'resnet18', device = 'cuda'):\n        super(Encoder, self).__init__()\n        self.backbone = timm.create_model(backbone, pretrained = True)\n        self.List = list(self.backbone.children())[:-2]\n        self.device = device\n    def forward(self,X):\n        X = X.to(self.device).float()\n        outputs = []\n        for i,layer in enumerate(self.List):\n            X = layer(X)\n            if i > 1:\n                outputs.append(X)\n        return outputs\n\nclass ResidualLayer(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels):\n        super(ResidualLayer, self).__init__()\n        self.resblock = nn.Sequential(nn.Conv2d(in_channels, out_channels,\n                                                kernel_size=3, padding=1, bias=False),\n                                      nn.ReLU(True),\n                                      nn.Conv2d(out_channels, out_channels,\n                                                kernel_size=1, bias=False))\n        self.conv = nn.Conv2d(in_channels*2, out_channels,\n                                                kernel_size=3, padding=1, bias=False)\n\n    def forward(self, input_1,input_2):\n        Y = input_1 + self.resblock(input_1)\n        Y = T.cat((Y,input_2),dim=1)\n        return self.conv(Y)\n\nclass Decoder(nn.Module):\n    def __init__(self):\n        super(Decoder, self).__init__()\n        self.upsample = nn.Upsample(scale_factor=2, mode = 'bilinear')\n        self.res1 = ResidualLayer(256,256)\n        self.res2 = ResidualLayer(128,128)\n        self.res3 = ResidualLayer(64,64)\n        self.res4 = ResidualLayer(64,64)\n        self.conv1 = nn.Conv2d(512,256,(3,3),padding = 1)  \n        self.conv2 = nn.Conv2d(256,128,(3,3),padding = 1)  \n        self.conv3 = nn.Conv2d(128,64,(3,3),padding = 1)\n        self.conv4 = nn.Conv2d(64,64,(3,3),padding = 1)\n        self.out = nn.Conv2d(64,3,(1,1))\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self,outputs):\n        X = self.upsample(outputs[-1])\n        X = F.relu(self.conv1(X))\n        X = self.res1(X,outputs[-2])\n        X = self.upsample(X)\n        X = F.relu(self.conv2(X))\n        X = self.res2(X,outputs[-3])\n        X = self.upsample(X)\n        X = F.relu(self.conv3(X))\n        X = self.res3(X,outputs[-5])\n        X = self.upsample(X)\n        X = F.relu(self.conv4(X))\n        X = self.res4(X,outputs[-6])\n        return self.out(X)\n    \nclass DAE_UNet(nn.Module):\n    def __init__(self,device='cuda'):\n        super(DAE_UNet,self).__init__()\n        self.encoder = Encoder()\n        self.decoder = Decoder()\n        self.to(device)\n        \n    def forward(self,X):\n        X = self.encoder(X)\n        X = self.decoder(X)\n        return X","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:32.504397Z","iopub.execute_input":"2021-10-30T18:47:32.505224Z","iopub.status.idle":"2021-10-30T18:47:32.531487Z","shell.execute_reply.started":"2021-10-30T18:47:32.505178Z","shell.execute_reply":"2021-10-30T18:47:32.530384Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"class Data(Dataset):\n    def __init__(self, dir_=\"../input/ai-club-inductions-21-image-enhancement/\", input_size=(224,224), output_size=(112, 112),training = True):\n        super().__init__()\n        self.training = training\n        self.directory = dir_\n        if self.training:\n            self.raw_files = sorted(os.listdir(self.directory+str(\"raw\")))[30:]\n        else:\n            self.raw_files = sorted(os.listdir(self.directory+str(\"raw\")))[:30]\n        self.input_size = input_size\n        self.output_size = output_size\n        self.preprocess = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n\n    def __len__(self): return len(self.raw_files)\n    \n    def __getitem_internal__(self, idx, preprocess=True):\n        raw_path = self.directory+str(\"raw/\")+self.raw_files[idx]\n        enhanced_path = self.directory+str(\"enhanced/\")+self.raw_files[idx]\n        raw_image = cv2.imread(raw_path)\n        enhanced_image = cv2.imread(enhanced_path)\n        raw_image = cv2.resize(raw_image,self.input_size)\n        enhanced_image = cv2.resize(enhanced_image,self.output_size)\n        enhanced_image = transforms.ToTensor()(np.array(enhanced_image))\n        if preprocess:\n            raw_image = self.preprocess(np.array(raw_image))\n        else:\n            raw_image = transforms.ToTensor()(np.array(raw_image))\n        return (raw_image,enhanced_image)\n\n    def __getitem__(self, idx):\n        return self.__getitem_internal__(idx, True)\n    \n    def raw(self, idx):\n        return self.__getitem_internal__(idx, False)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:32.534758Z","iopub.execute_input":"2021-10-30T18:47:32.535632Z","iopub.status.idle":"2021-10-30T18:47:32.551546Z","shell.execute_reply.started":"2021-10-30T18:47:32.535421Z","shell.execute_reply":"2021-10-30T18:47:32.550447Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"train_dataloader = Data()\nprint(\"Train :\",train_dataloader.__len__())\nval_dataloader = Data(training=False)\nprint(\"Val :\",val_dataloader.__len__())","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:32.555794Z","iopub.execute_input":"2021-10-30T18:47:32.556682Z","iopub.status.idle":"2021-10-30T18:47:32.574318Z","shell.execute_reply.started":"2021-10-30T18:47:32.556633Z","shell.execute_reply":"2021-10-30T18:47:32.573402Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"for i in range(5,9):\n    raw_normalized, enhanced = train_dataloader[i]\n    raw,_ = train_dataloader.raw(i)\n    fig, ax = plt.subplots(1, 3,figsize=(12,4))\n    ax[0].imshow(raw.permute(1,2,0).numpy())        \n    ax[0].set_xticks([])\n    ax[0].set_yticks([])\n    ax[0].title.set_text('RAW IMAGE')\n    ax[1].imshow(raw_normalized.permute(1,2,0).numpy())        \n    ax[1].set_xticks([])\n    ax[1].set_yticks([])\n    ax[1].title.set_text('RAW NORMALIZED IMAGE')\n    ax[2].imshow(enhanced.permute(1,2,0).numpy())        \n    ax[2].set_xticks([])\n    ax[2].set_yticks([])\n    ax[2].title.set_text('ENHANCED IMAGE')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:32.575604Z","iopub.execute_input":"2021-10-30T18:47:32.576789Z","iopub.status.idle":"2021-10-30T18:47:34.059810Z","shell.execute_reply.started":"2021-10-30T18:47:32.576744Z","shell.execute_reply":"2021-10-30T18:47:34.058831Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class VGGPerceptualLoss(T.nn.Module):\n    def __init__(self, resize=True):\n        super(VGGPerceptualLoss, self).__init__()\n        blocks = []\n        blocks.append(torchvision.models.vgg16(pretrained=True).features[:2].eval())\n        blocks.append(torchvision.models.vgg16(pretrained=True).features[2:4].eval())\n        blocks.append(torchvision.models.vgg16(pretrained=True).features[4:9].eval())\n        blocks.append(torchvision.models.vgg16(pretrained=True).features[9:16].eval())\n        blocks.append(torchvision.models.vgg16(pretrained=True).features[16:23].eval())\n        for bl in blocks:\n            for p in bl.parameters():\n                p.requires_grad = False\n            \n        self.blocks = T.nn.ModuleList(blocks)\n        self.transform = T.nn.functional.interpolate\n        self.mean = T.nn.Parameter(T.tensor([0.485, 0.456, 0.406], device='cuda').view(1,3,1,1))\n        self.std = T.nn.Parameter(T.tensor([0.229, 0.224, 0.225], device='cuda').view(1,3,1,1))\n        self.resize = resize\n\n    def forward(self, input, target):\n        if input.shape[1] != 3:\n            input = input.repeat(1, 3, 1, 1)\n            target = target.repeat(1, 3, 1, 1)\n        input = (input-self.mean) / self.std\n        target = (target-self.mean) / self.std\n        if self.resize:\n            input = self.transform(input, mode='bilinear', size=(224, 224), align_corners=False)\n            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False)\n        loss = 0.0\n        x = input\n        y = target\n        for block in self.blocks:\n            x = block(x)\n            y = block(y)\n            loss += T.nn.functional.l1_loss(x, y)\n        return loss\n    \nmodel = DAE_UNet()\ncriterion1 = nn.MSELoss()\nperceptual_loss = VGGPerceptualLoss().to(device)\nssim = SSIM(data_range=255, size_average=True, channel=3)\n\ndef loss_fn(predicted,target):\n    return perceptual_loss(predicted,target)        #+1 - ssim(predicted,target)\n\n@T.no_grad()\ndef validation(model, loader, loss_fn):\n    vlosses = []\n    v = tqdm(loader)\n    model.eval()\n    for i,(input_image,gt_image) in enumerate(v):\n        input_image,gt_image = input_image.to(device), gt_image.to(device)\n        y_pred = model(input_image)\n        vloss = loss_fn(y_pred,gt_image)\n        vlosses.append(vloss.item())\n    j = random.randint(0,29)\n    raw_normalized, enhanced = train_dataloader[j]\n    raw,_ = train_dataloader.raw(j)\n    y_pred = model(raw_normalized.unsqueeze(dim=0))\n    fig, ax = plt.subplots(1, 3,figsize=(12,4))\n    ax[0].imshow(raw.cpu().permute(1,2,0).numpy())        \n    ax[0].set_xticks([])\n    ax[0].set_yticks([])\n    ax[0].title.set_text('INPUT IMAGE')\n    ax[1].imshow(y_pred[0].cpu().permute(1,2,0).numpy())        \n    ax[1].set_xticks([])\n    ax[1].set_yticks([])\n    ax[1].title.set_text('PREDICTED IMAGE')\n    ax[2].imshow(enhanced.cpu().permute(1,2,0).numpy())        \n    ax[2].set_xticks([])\n    ax[2].set_yticks([])\n    ax[2].title.set_text('GT IMAGE')\n    plt.show()\n    model.train()\n    return np.array(vlosses).mean()\n\nmodel.load_state_dict(T.load(\"./model.pth\", map_location=device))\noptimizer = T.optim.Adam(model.parameters(), lr=0.0001)\n\nscheduler = T.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.5,patience=1,verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:34.061705Z","iopub.execute_input":"2021-10-30T18:47:34.062297Z","iopub.status.idle":"2021-10-30T18:47:43.282037Z","shell.execute_reply.started":"2021-10-30T18:47:34.062256Z","shell.execute_reply":"2021-10-30T18:47:43.280963Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"batch_size = 50\nEPOCHES = 5\n\ntrain_loader = DataLoader(train_dataloader,batch_size=batch_size,shuffle=False, num_workers=0, sampler=SubsetRandomSampler(list(range(len(train_dataloader)))),\n                             drop_last=False)\nval_loader = DataLoader(val_dataloader,batch_size=batch_size,shuffle=False,\n                              num_workers=0,\n                              sampler=SubsetRandomSampler(list(range(len(val_dataloader)))),\n                             drop_last=False)\nbest_loss = None\nraw_line0 = r'''Epoch[{}]    |    Lr:{}'''\nraw_line1 = r'''TOTAL Train loss: {}  |  TOTAL Val loss: {}  |  Time:{:.1f} min '''","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:43.283576Z","iopub.execute_input":"2021-10-30T18:47:43.283889Z","iopub.status.idle":"2021-10-30T18:47:43.292872Z","shell.execute_reply.started":"2021-10-30T18:47:43.283845Z","shell.execute_reply":"2021-10-30T18:47:43.291514Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, EPOCHES+1):\n        losses = []\n        start_time = time.time()\n        t = tqdm(train_loader)\n        model.train()\n        for i,(input_image,gt_image) in enumerate(t):\n            input_image,gt_image = input_image.to(device), gt_image.to(device)\n            optimizer.zero_grad()\n            y_pred = model(input_image)\n            loss = loss_fn(y_pred,gt_image)\n            loss.backward()\n            optimizer.step()\n            losses.append(loss.item())\n        vloss = validation(model, val_loader, loss_fn)\n        print(raw_line0.format(epoch,optimizer.param_groups[0][\"lr\"]))\n        print(raw_line1.format(np.array(losses).mean(),vloss,(time.time()-start_time)/60**1))\n\n        if best_loss == None:\n            best_loss = vloss\n            T.save(model.state_dict(), 'model.pth')\n            print(\"saving model ..\")\n        if vloss < best_loss:\n            best_loss = vloss\n            T.save(model.state_dict(), 'model.pth')\n            print(\"saving model ..\")\n        scheduler.step(vloss)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:47:43.295343Z","iopub.execute_input":"2021-10-30T18:47:43.295701Z","iopub.status.idle":"2021-10-30T18:52:24.292617Z","shell.execute_reply.started":"2021-10-30T18:47:43.295655Z","shell.execute_reply":"2021-10-30T18:52:24.291665Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class TestData(Dataset):\n    def __init__(self, dir_=\"../input/ai-club-inductions-21-image-enhancement/\", input_size=(224,224), output_size=(112, 112)):\n        super().__init__()\n        self.directory = dir_\n        self.raw_files = os.listdir(self.directory+str(\"test\"))\n        self.input_size = input_size\n        self.output_size = output_size\n        self.preprocess = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n\n    def __len__(self): return len(self.raw_files)\n    \n    def __getitem_internal__(self, idx, preprocess=True):\n        raw_path = self.directory+str(\"test/\")+self.raw_files[idx]\n        enhanced_path = str(\"../input/test-gt/test_gt/\")+self.raw_files[idx]\n        raw_image = cv2.imread(raw_path)\n        enhanced_image = cv2.imread(enhanced_path)\n        raw_image = cv2.resize(raw_image,self.input_size)\n        enhanced_image = cv2.resize(enhanced_image,self.output_size)\n        enhanced_image = transforms.ToTensor()(np.array(enhanced_image))\n        if preprocess:\n            raw_image = self.preprocess(np.array(raw_image))\n        else:\n            raw_image = transforms.ToTensor()(np.array(raw_image))\n        return (raw_image,enhanced_image)\n\n    def __getitem__(self, idx):\n        return self.__getitem_internal__(idx, True)\n    \n    def raw(self, idx):\n        return self.__getitem_internal__(idx, False)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:52:24.294410Z","iopub.execute_input":"2021-10-30T18:52:24.295394Z","iopub.status.idle":"2021-10-30T18:52:24.312450Z","shell.execute_reply.started":"2021-10-30T18:52:24.295340Z","shell.execute_reply":"2021-10-30T18:52:24.310954Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"test_dataloader = TestData()\nprint(\"Val :\",len(test_dataloader))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:52:24.314482Z","iopub.execute_input":"2021-10-30T18:52:24.315077Z","iopub.status.idle":"2021-10-30T18:52:24.332908Z","shell.execute_reply.started":"2021-10-30T18:52:24.315008Z","shell.execute_reply":"2021-10-30T18:52:24.331713Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"import os\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage import io\n\ndef evaluate(p_img,gt_img):\n    s = ssim(p_img, gt_img, multichannel=True)\n    return s","metadata":{"execution":{"iopub.status.busy":"2021-10-30T18:52:24.334819Z","iopub.execute_input":"2021-10-30T18:52:24.335793Z","iopub.status.idle":"2021-10-30T18:52:24.344468Z","shell.execute_reply.started":"2021-10-30T18:52:24.335714Z","shell.execute_reply":"2021-10-30T18:52:24.342968Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(T.load(\"./model.pth\",map_location=T.device('cuda')))\nmodel.eval()\nssim_t = []\nfor i in range(len(test_dataloader)):\n    raw_normalized, enhanced = test_dataloader[i]\n    raw,_ = test_dataloader.raw(i)\n    y_pred = model(raw_normalized.unsqueeze(dim=0))\n    raw = raw.permute(1,2,0).numpy()\n    enhanced = enhanced.permute(1,2,0).numpy()\n    y_pred = y_pred.squeeze(dim=0).permute(1,2,0).detach().cpu().numpy()\n    a = evaluate(y_pred,enhanced)\n    ssim_t.append(a)\n    if i < 10:\n        print(\"SSIM METRIC :\",a)\n        fig, ax = plt.subplots(1, 3,figsize=(12,4))\n        ax[0].imshow(raw)        \n        ax[0].set_xticks([])\n        ax[0].set_yticks([])\n        ax[0].title.set_text('INPUT IMAGE')\n        ax[1].imshow(y_pred)        \n        ax[1].set_xticks([])\n        ax[1].set_yticks([])\n        ax[1].title.set_text('PREDICTED IMAGE')\n        ax[2].imshow(enhanced)        \n        ax[2].set_xticks([])\n        ax[2].set_yticks([])\n        ax[2].title.set_text('GT IMAGE')\n        plt.show()\nprint(\"***********************************************\")\nprint(\"AVERAGE SSIM METRIC :\",sum(ssim_t)/len(ssim_t))\nprint(\"***********************************************\")","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:04:19.965537Z","iopub.execute_input":"2021-10-30T19:04:19.965869Z","iopub.status.idle":"2021-10-30T19:04:29.320726Z","shell.execute_reply.started":"2021-10-30T19:04:19.965837Z","shell.execute_reply":"2021-10-30T19:04:29.319645Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}